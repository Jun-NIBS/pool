We first introduce mathematical notation that allows precise discussion of the POOL methodology. Let $E$ be the set of peptides over which we would like to search.
In our application, the set $E$ will be the set of peptides of length less than 38 amino acids.
For any peptide sequence $e \in E$, let $y(e) \in \{0, 1\}$ be a binary label indicating whether
peptide $e$ is active.  We suppose that this label can be observed directly through experiment, but is otherwise unknown {\it a priori}.
In our application, we consider two definitions of $y(e)$, depending on whether we are searching for peptides with Sfp-specific or AcpS-specific activity:
\begin{itemize}
\item When searching for peptides with Sfp-specific activity, we let $y(e)$ be $1$ if the peptide is a substrate for both Sfp and AcpH, but is not a substrate for AcpS.  We call this an \enquote{Sfp-specific hit}.
\item When searching for peptides with AcpS-specific activity, we let $y(e)$ be $1$ if the peptide is a substrate for both AcpS and AcpH, but is not a substrate for Sfp.  We call this an \enquote{AcpS-specific hit}.
\end{itemize}

POOL searches for peptides that are active, and for which another given fitness function $f(e)$ is large.   We assume that this fitness function can be observed directly without requiring a physical experiment. In our application, the fitness is negative one times the length of the peptide.  The negative one is present because we will want fitness to be large, but we want the length to be small.

Our goal, in terms of the notation we have defined, is find a peptide $e\in E$ for which $y(e)=1$ and for which $f(e)$ is as large as possible.  We can write this problem as,
\begin{equation}
  \underset{e \in E, y(e) = 1}{\arg\max} \, f(e).
  \label{eq:general problem}
\end{equation}

% <<<<<<< HEAD
However, we typically cannot solve this problem directly because $y(e)$ has only been observed for those peptides on which we have performed an experiment, which is typically only a small fraction of the peptides in our search space $E$, and the additional experimental effort required to observe $y(e)$ for all peptides in $E$ is simply beyond the realm of feasibility.  
For example, in our application, $E$ contains more than $2 \times 10^{49}$ peptides, and our current experimental approach allows testing roughly 500 peptides every month.  At this rate, we would require $3 \times 10^{45}$ years to test all of the peptides.
Even if we restricted $E$ to those peptides of length 10 or less, we would require $6 \times 10^{9}$ years.

POOL is designed for these situations in which the number of peptides we can evaluate is substantially smaller than the search space.  
It assumes that we have available the values of $y(e)$ for a small number of previously evaluated peptides (we refer to this as ``training data''), and that we can also evaluate $y(e)$ for a set of new peptides chosen by POOL.  POOL supposes that peptides are evaluated in batches, and we let $k$ denote the number of peptides in a batch.  POOL may be applied once, to recommend a single batch of peptides to test, or it may be applied repeatedly, each time adding the results from previously tested batches to the training data.

In our application, our training data initially contained data allowing partial evaluation of $y(e)$, for 14 proteins (length longer than 38) from the literature \jwcomment{Add cites to papers for the initial data}, as well as one length-11 peptide obtained using phage display by~\cite{yin2005genetically}.
We did 5 rounds using a batch size $k$ that varied somewhat from batch to batch, but remained approximately equal to 500.

POOL uses such limited evaluation budgets to best support solving \eqref{eq:general problem}, in the specific sense of maximizing the probability of finding an active peptide whose quality is better than some target quality $b$.
It consists of three steps: first, a prediction step, in which a machine learning method (Naive Bayes, customized for peptide activity) provides a joint probability distribution over peptide activity; second, a probability-of-improvement step, in which we use value-of-information analysis to define the quality of a set of peptides to test; and third, a greedy optimization step, in which we use a greedy algorithm to find a set of peptides to test that provides a large probability of improvement.

\pfcomment{We need to make sure to reflect these names, prediction, probability-of-improvement, greedy optimization, through the rest of the paper.}

We discuss POOL in more detail in the following sections: Section \ref{sec:existing approaches} reviews existing alternate approaches to allocating experimental effort in support of solving \eqref{eq:general problem}; Section \ref{sec:stat model} describes the machine learning model POOL uses to predict $y(e)$; Section \ref{sec:prob improvement} defines the probability of improvement criterion used by POOL; Section \ref{sec:contrast with predict-then-optimize} contrasts this probability of improvement approach to existing approaches; and Section \ref{sec:greedy algorithm}
presents the greedy approximation algorithm for finding the set of peptides to test with largest probability of improvement, and which completes the description of the POOL methodology.
Section \ref{sec:greedy algorithm} further provides a theoretical guarantee on the quality of this greedy approximation algorithm (\ref{sec:lower bound}), discusses intuition (\ref{sec:reduced form} and \ref{sec:intuition}) and computation (\ref{sec:MINLP approach} and \ref{sec:MAP approach}) of this greedy step.

Section \ref{sec:generality} and Section \ref{sec:extension} discuss extension of POOL: Section \ref{sec:generality} discusses the generality of our proposed approach, pointing out that probability-of-improvement and greedy optimization can be used with a broad class of machine learning models beyond Naive Bayes, while still maintaining the performance guarantee; Section \ref{sec:extension} discusses an extension to the search for peptides with multiple types of activities. 

Finally, Section \ref{sec:application} discusses how POOL was applied to successfully find peptides with specific enzymatic activity, creating a reversible protein labeling system. 