\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,mathtools}
\usepackage{bbm}
\newcommand{\E}{\mathbb{E}}
\newcommand{\EI}{\mathrm{EI}}
\newcommand{\PI}{\text{P}^*}
\newcommand{\mb}{\mathbf}

\begin{document}
\section{Introduction}

\section{Problem Statement and Application}
We first describe the application that motivates our research, and then we provide mathematical formalism to address a more general problem. In the last sub-section we derive our method in solving this problem.

\subsection{Motivating application}
We have two enzymes (Sfp from {\it Bacillus subtilis}, and PaAcpH from {\it Pseudomonas aeruginosa}), and a collection of peptides that can potentially act as a substrate for one or both of these enzymes.  Our goal is to find a peptide that acts as a substrate for both of these enzymes, and is as short as possible.

To support this goal, we can do lab experiments, in which we synthesize a peptide and test, for each enzyme, whether it is a substrate.We need to find a policy that suggests which peptide to synthesize and test next, so as to reach our goal with as few experiments as possible.

Experiments have parallel setup, thus can be done with a batch of peptides at a time, and so the algorithm suggests a batch of peptides at a time, waiting for the results from the experiment before suggesting the next batch of peptides.
A large collection of peptides would be considered by the algorithm for potential synthesis and testing, e.g., all peptides with length less than a given threshold.  That is, we would consider more peptides than just those that are sub-peptides of peptides from the literature known to be substrates for one enzyme.

\subsection{General Problem Statement}
We now formalize it as an active learning problem, which represents a class of interactive learning problems, not only limited to our motivating application.

In a search space $E$, for each element $x \in E$, it has an unknown binary label $y(x)=\{0,1\}$. There is a known deterministic function $f(x)$ measuring the quality of $x$. Our goal is to find $x$ such that it has positive label and its quality function $f(x)$ is minimum.

In order to obtain labels of exemplars, we can do a batch of experiments, which evaluate a subset $S \subseteq E$ and obtain labels at each time. we measure quality of $S$ by
\begin{equation} \label{eq:fS}
f^*(S)= \begin{dcases}
 \underset{x \in S:y(x)=1}{\min} f(x) & \text{if \,} \{x \in S:y(x)=1\} \neq \emptyset \\
 \infty  & \text{if \,} \{x \in S:y(x)=1\} = \emptyset
 \end{dcases}
\end{equation}

%Let $E$ be any set. For each element $x\in E$, we define a function $f(x)$ that measures the quality of $x$. Larger or smaller values of $f(x)$ may be favored depending on different problem settings. From now on, we assume, without losing generality that smaller values of $f(x)$ are preferred, and for any subset $S\subseteq E$, we measure the quality of $S$ as:
%
%\begin{equation*}
%f^*(S) = \min_{x\in S:\mathbf{h}(x)=0}f(x)
%\end{equation*}
%
%where $\mathbf{h}(x)=(h_1(x),\cdots,h_m(x))$ is a set of constraints that define a subset of "effective elements". We wish to find $S\subseteq E$ with $f^*(S)$ as small as possible, while $S$ it self must satisfy some constraints. A typical constraint is the cardinality of $S$, we usually prefer smaller sets. Other constraints can be applied in different problems.

Let $b$ be a target value and we wish to find $S\subseteq E$ such that $f^*(S)$ is, in some sense, better than $b$. Specifically, we consider the following two measures:
\begin{equation} \label{eq:twomeasure}
\begin{align*}
&\text{Probability of Improvement: }&\PI(S) = \mathbb{P}(f^*(S) < b)\\
&\text{Expected Improvement: }&\EI(S) = \E [(b-f^*(S))]
\end{align*}
\end{equation}
We wish to find $S$ that maximize one of these two measures. Let $g(S)$ be either $\PI(S)$ or $\EI(S)$ and let the cardinality of $S$ be the only constraint on $S$. Our goal is then:

\begin{equation} \label{eq:opt}
\max_{S\subseteq E:|S|<k}g(S)
\end{equation}

\subsection{Solution Method for EI}
If $g(S)$ is $\EI(S)$, from equation \eqref{eq:twomeasure} \eqref{eq:opt}, our goal becomes
\begin{equation} \label{eq:maxEI}
\underset{S \subseteq E:|S| \leq k}{\max} \E \left[ (b-f^*(S))^+ \right]
\end{equation}
We first prove that the objective function is submodular, and then describe our greedy approach to solve \eqref{eq:maxEI}, finally we show that we have guarantee for our greedy policy compared with optimal policy.
\subsubsection{Submodularity}
\subsubsection{Greedy Approach}
Suppose we have chosen $S=\{x_1, x_2, \ldots, x_n\}$ as a batch of points we are going to evaluate next, and if we want to incorporate one more point $e$, which is distinct from $x_1, x_2, \ldots, x_n$, such that the expected improvement increases most, we use the following criterion to find $e$:
\begin{equation} \label{eq:finde}
\underset{e \in E \backslash S}{\mathrm{arg}\max} \, \E \left[ (b-f^*(S \cup \{e\}))^+ \right] 
\end{equation}
From \eqref{eq:fS} we write expected improvement part in \eqref{eq:opt} as
\begin{align*}
\E \left[ (b-f^*(S))^+ \right] &= \E [b-\underset{x \in S \cup \{e\}:y(x)=1}{\min} f(x)] \\
                  &= 
                  \begin{dcases}
                    \E [b- f^*(S)] & \text{if $y(e)=0$ ,} \\
                    \E [b- \min \{f(e), f^*(S)\}]       & \text{if $y(e)=1$ ,}
                    \end{dcases} \\
                  &= \E [b-f^*(S) + \mathbbm{1}_{\{y(e)=1, f(e) < f^*(S)\}} [f^*(S)-f(e)] ]
\end{align*}
After some algebra we can write \eqref{eq:finde} as
\begin{align*}
&\underset{e \in E \backslash S}{\mathrm{arg}\max} \E [ \mathbbm{1}_{\{y(e)=1, f(e) < f^*(S)\}} [f^*(S)-f(e)] ] \\
%&=\underset{e \in E \backslash S}{\mathrm{arg}\max} \E [ \E [\mathbbm{1}_{\{y(e)=1, f(e) < f^*(S)\}} [f^*(S)-f(e)] | f^*(S)]\\
%&= \underset{e \in E \backslash S}{\mathrm{arg}\max} \E [ \mathbbm{1}_{\{f(e)<f^*(S)\}} \mathbb{P} (y(e)=1 | f^*(S)) [f^*(S)-f(e)]] \\
&= \underset{e \in E \backslash S}{\mathrm{arg}\max} \sum_{i=1}^{|S|} \mathbb{P} (y(e)=1, y(x_i)=1, y(x_j)=0, \forall j <i) [f(x_i)-f(e)]^+ \\
&+ \mathbb{P} (y(e)=1, y(x_j)=0, \forall j) [b-f(e)]^+
\end{align*}
where $f(x_i)<=f(x_j)$ for $\forall i<j, x_i,x_j \in S$.
Since 
\begin{align*}
&\mathbb{P} (y(e)=1, y(x_i)=1, y(x_j)=0, \forall j <i)\\
&= \mathbb{P}(y(x_1)=0) \mathbb{P}(y(x_2)=0|y(x_1)=0) \ldots \mathbb{P}(y(e)=1|\mathcal{F}(x_1,x_2,\ldots,x_i)\\
&\propto \mathbb{P}(y(e)=1|\mathcal{F}(x_1,x_2,\ldots,x_i)
\end{align*}



\end{document}